import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import time
import streamlit as st
from llm.sql_executor import answer_question
from cache.cache_metrics import get_metrics, hit_rate

st.set_page_config(
    page_title="Text-to-SQL GenAI Dashboard",
    page_icon="ðŸ§ ",
    layout="wide"
)

st.title("Text-to-SQL GenAI System")
st.caption("Neon PostgreSQL + LangChain + Multi-Tier Cache")


if "history" not in st.session_state:
    st.session_state.history = []

if "current_item" not in st.session_state:
    st.session_state.current_item = None



st.sidebar.header("Query History")

if st.session_state.history:

    for i, item in enumerate(reversed(st.session_state.history)):

        label = item["question"]
        if len(label) > 40:
            label = label[:40] + "..."

        if st.sidebar.button(label, key=f"hist_{i}"):
            st.session_state.current_item = item

else:
    st.sidebar.write("No queries yet")



st.sidebar.divider()
st.sidebar.header(" Example Questions")

examples = [
    "Show all customers who are from Alabama",
    "List all customers",
    "Show customers from California",
    "List customers with highest spending"
]

for ex in examples:
    if st.sidebar.button(ex):
        st.session_state.current_item = None
        st.session_state.example_question = ex



default_q = st.session_state.get("example_question", "")

question = st.text_input(
    "Ask a question about your database:",
    value=default_q,
    placeholder="e.g., Show all customers from Alabama"
)


if st.button("Generate Answer") and question:

    start_time = time.time()

    with st.spinner("Processing..."):

        try:
            sql, df, source, usage = answer_question(question)

            elapsed = time.time() - start_time

            item = {
                "question": question,
                "sql": sql,
                "df": df,
                "source": source,
                "time": elapsed,
                "usage": usage
            }

            st.session_state.history.append(item)
            st.session_state.current_item = item

            # Clear example question after execution
            st.session_state.example_question = ""

        except Exception as e:
            st.error(f"Error: {e}")



item = st.session_state.current_item

if item:

    # Cache Source Indicator
    if item["source"] == "L1-cache":
        st.success("Tier-1 Memory Cache Hit")
    elif item["source"] == "L2-cache":
        st.info("Tier-2 Persistent Cache Hit")
    else:
        st.warning("Generated by LLM (Cache Miss)")

    # Execution Time
    st.caption(f"Execution time: {item['time']:.3f} seconds")

    # Question
    st.subheader("Question")
    st.write(item["question"])

    # SQL Output
    st.subheader("Generated SQL")
    st.code(item["sql"], language="sql")

    # Query Result
    st.subheader("Query Result")

    st.dataframe(
        item["df"],
        width="stretch"  
    )

    if item["usage"]:

        st.subheader("Token Usage")

        col1, col2, col3, col4 = st.columns(4)

        col1.metric("Prompt Tokens", item["usage"]["prompt_tokens"])
        col2.metric("Completion Tokens", item["usage"]["completion_tokens"])
        col3.metric("Total Tokens", item["usage"]["total_tokens"])
        col4.metric("Cost (USD)", f"${item['usage']['cost_usd']:.6f}")
        st.caption(f"Rows returned: {len(item['df'])}")

    if item["source"] != "LLM":
        st.success("Saved tokens via cache")

    # CSV Download
    csv = item["df"].to_csv(index=False).encode("utf-8")

    st.download_button(
        label="Download results as CSV",
        data=csv,
        file_name="query_results.csv",
        mime="text/csv"
    )



st.divider()
st.subheader(" Cache Metrics")

metrics = get_metrics()

col1, col2, col3, col4 = st.columns(4)

col1.metric("L1 Hits", metrics["l1_hits"])
col2.metric("L2 Hits", metrics["l2_hits"])
col3.metric("Misses", metrics["misses"])
col4.metric("Hit Rate", f"{hit_rate() * 100:.2f}%")